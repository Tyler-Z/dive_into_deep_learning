{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1d657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f00802",
   "metadata": {},
   "source": [
    "## 标量由只有一个元素的张量表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8e934b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.]), tensor([6.]), tensor([1.5000]), tensor([9.]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([3.0])\n",
    "y = torch.tensor([2.0])\n",
    "\n",
    "x+y, x*y, x/y, x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67190f",
   "metadata": {},
   "source": [
    "## 可以将向量视为标量值组成的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae9a0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ee5ca8",
   "metadata": {},
   "source": [
    "## 通过张量的索引来访问任一元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f8d733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0628030",
   "metadata": {},
   "source": [
    "## 访问张量的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b5ccaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116278cd",
   "metadata": {},
   "source": [
    "## 只有一个轴的张量，形状只有一个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec867529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e714786",
   "metadata": {},
   "source": [
    "## 通过指定两个分量 m 和 n 来创建一个形状为 m x n 的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb12b3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20).reshape(5, 4)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e5c44",
   "metadata": {},
   "source": [
    "## 矩阵的转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c463812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8, 12, 16],\n",
       "        [ 1,  5,  9, 13, 17],\n",
       "        [ 2,  6, 10, 14, 18],\n",
       "        [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878bceb3",
   "metadata": {},
   "source": [
    "## 对称矩阵（symmetric matrix） A等于其转置：A = A^T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f93c01fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 0, 4],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "defc9d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B == B.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19dd34b",
   "metadata": {},
   "source": [
    "## 向量是标量的推广，矩阵是向量的推广，我们可以构建具有更多轴的数据结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab6f8b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(24).reshape(2, 3, 4)    # 在1个三维张量中，有2个二维矩阵，每个二维矩阵有3个向量，每个向量有4个标量\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d6e15",
   "metadata": {},
   "source": [
    "## 给定具有相同形状的任何两个张量，任何按元素二元运算的结果都将是相同形状的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f06a0932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20, dtype=torch.float32).reshape(5,4)\n",
    "B = A.clone()    # 通过分配新内存，将A的一个副本分配给B\n",
    "A, A+B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693172f1",
   "metadata": {},
   "source": [
    "## 两个矩阵 按元素乘法 称为 哈达玛积 （Hadamard product） 数学符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "727400ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.],\n",
       "        [144., 169., 196., 225.],\n",
       "        [256., 289., 324., 361.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68cffd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "a + X, (a * X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f86cfe5",
   "metadata": {},
   "source": [
    "## 计算其元素的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cabd8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor(6.))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4, dtype=torch.float32)\n",
    "x, x.sum()  # 求和的值，是标量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740328c3",
   "metadata": {},
   "source": [
    "## 表示任意形状张量的元素和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6abf618b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), tensor(190.))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71bc94cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 4]), tensor(780.))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(40, dtype=torch.float32).reshape(2, 5, 4)\n",
    "A.shape, A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4975eb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]],\n",
       "\n",
       "        [[20., 21., 22., 23.],\n",
       "         [24., 25., 26., 27.],\n",
       "         [28., 29., 30., 31.],\n",
       "         [32., 33., 34., 35.],\n",
       "         [36., 37., 38., 39.]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f1b2b",
   "metadata": {},
   "source": [
    "# 指定求和汇总张量的轴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5af434fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[20, 22, 24, 26],\n",
       "         [28, 30, 32, 34],\n",
       "         [36, 38, 40, 42],\n",
       "         [44, 46, 48, 50],\n",
       "         [52, 54, 56, 58]]),\n",
       " torch.Size([5, 4]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把第一个维度进行求和（2），不管剩下的（5，4）\n",
    "# 对第一个维度求和：把两个【4 x 5】矩阵相加\n",
    "A_sum_axis0 = A.sum(axis=0)    \n",
    "A_sum_axis0, A_sum_axis0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd4fe1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 40,  45,  50,  55],\n",
       "         [140, 145, 150, 155]]),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把第二个维度进行求和（5），不管剩下的（2，4）\n",
    "# 对第二个维度求和：把每个【4 x 5】矩阵，按列相加\n",
    "A_sum_axis1 = A.sum(axis=1)    \n",
    "A_sum_axis1, A_sum_axis1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b08eb33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([180, 190, 200, 210]), torch.Size([4]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把第一个和第二个维度进行求和（2， 5），不管剩下的（4）\n",
    "# 对第一个和第二个维度求和：把两个【4 x 5】矩阵，按列相加求总和，维度等于第三维\n",
    "A_sum_axis01 = A.sum(axis=[0,1])    \n",
    "A_sum_axis01, A_sum_axis01.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ca51b",
   "metadata": {},
   "source": [
    "### 对于axis的总结：\n",
    "\n",
    "- axis等于几，相当于把第几维消除。\n",
    "    - 例如torch.size(2, 5, 4), \n",
    "        - 当axis=0，相当于把[5,4]的【5】给消去，剩下的【2, 4】，是一个2行4列的矩阵\n",
    "        - 当axis=[1,2]，相当于把[5,4]的【5, 4】给消去，剩下的【2】，是一个长为2的向量        \n",
    "- 把第几维拍扁，其他维度保留？\n",
    "\n",
    "### 当keepdims = True， axis = 1 时\n",
    "- 原shape：(2, 5, 4)\n",
    "- 现shape：(2, 1, 5)\n",
    "\n",
    "### 当keepdims = True， axis = (1, 2) 时\n",
    "- 原shape：(2, 5, 4)\n",
    "- 现shape：(2, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b952ce4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.arange(24).reshape(2,3,4)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dafeb3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[12, 14, 16, 18],\n",
       "         [20, 22, 24, 26],\n",
       "         [28, 30, 32, 34]]),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axis = 0\n",
    "u_sum_axis_0 = u.sum(axis=0)    # 等价于 u[0, :, :] + u[1, :, :]\n",
    "u_sum_axis_0, u_sum_axis_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "351685f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12, 14, 16, 18],\n",
       "        [20, 22, 24, 26],\n",
       "        [28, 30, 32, 34]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u[0, :, :]  + u[1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "63f442ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[12, 15, 18, 21],\n",
       "         [48, 51, 54, 57]]),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axis = 1\n",
    "u_sum_axis_1 = u.sum(axis=1)\n",
    "u_sum_axis_1, u_sum_axis_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "de970d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6, 22, 38],\n",
       "         [54, 70, 86]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axis = 2\n",
    "u_sum_axis_2 = u.sum(axis=2)\n",
    "u_sum_axis_2, u_sum_axis_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a942a7d",
   "metadata": {},
   "source": [
    "## 平均值（mean或average）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7eecfb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19.5000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bc44781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19.5000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum()/A.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf4582",
   "metadata": {},
   "source": [
    "## 计算总和或均值时保持轴数不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27198b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 6.],\n",
       "         [22.],\n",
       "         [38.],\n",
       "         [54.],\n",
       "         [70.]]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20, dtype=torch.float32).reshape(5,4)\n",
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "A, sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020b9c76",
   "metadata": {},
   "source": [
    "## 通过广播，将A 除以 sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95092654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
       "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
       "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
       "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
       "        [0.2286, 0.2429, 0.2571, 0.2714]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5708ade2",
   "metadata": {},
   "source": [
    "## 某个轴 计算A元素的积累总和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cddc15cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  6,  8, 10],\n",
       "        [12, 15, 18, 21],\n",
       "        [24, 28, 32, 36],\n",
       "        [40, 45, 50, 55]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766cafd5",
   "metadata": {},
   "source": [
    "## 点积是相同位置的按元素乘积的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4001c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(4, dtype=torch.float32)\n",
    "x, y, torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db451059",
   "metadata": {},
   "source": [
    "# 矩阵乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8dce64",
   "metadata": {},
   "source": [
    "## 通过执行按元素乘法，然后进行求和来表示两个向量的点积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0519a49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03b43c6",
   "metadata": {},
   "source": [
    "## 矩阵向量积 Ax 是一个长度为m的列向量，其第i个元素是是点积a_i^T * x_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7e26e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([0., 1., 2., 3.]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6dda3d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, x.shape, torch.mv(A, x)  # 矩阵向量的乘积，matrix vector multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "86cbf71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 我们可以将矩阵-矩阵乘法AB看作是简单地执行m次矩阵 - 向量积，并将结果拼接在一起，形成一个n x m 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9416a14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  6.],\n",
       "        [22., 22., 22.],\n",
       "        [38., 38., 38.],\n",
       "        [54., 54., 54.],\n",
       "        [70., 70., 70.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.ones(4, 3)\n",
    "torch.mm(A, B)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "950becb3",
   "metadata": {},
   "source": [
    "# 范数：向量或矩阵的长度\n",
    "\n",
    "## L2 范数是向量元素的平方和的平方根：\n",
    "\n",
    "<img src=\"./pic/L2范数.PNG\" width=200  heigth=200>\n",
    "\n",
    "\n",
    "## L1 范数是向量元素的绝对值之和：\n",
    "\n",
    "<img src=\"./pic/L1范数.PNG\" width=200  heigth=200>\n",
    "\n",
    "## 矩阵的 弗罗贝尼乌斯范数（Forbenius norm）是矩阵元素的平方和的平方根\n",
    "- 等价于把矩阵拉成一个向量，然后再求向量的范数\n",
    "\n",
    "<img src=\"./pic/F范数.PNG\"  width=200  heigth=200>\n",
    "\n",
    "## L2范数是针对向量而言的，F范数是针对矩阵而言的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <img src=\"./pic/L2范数.PNG\" style=\"float: left;\" width=200  heigth=200>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "95ec72b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L2 范数\n",
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69b3a224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1 范数\n",
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05152eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F范数\n",
    "torch.norm(torch.ones((4,9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec560f6b",
   "metadata": {},
   "source": [
    "### Q: 赋值语句为什么要多加一个括号？\n",
    "### A: 加括号相当于使用元组创建三维的tensor。也可以把里面的变为中括号，那就是使用列表创建三维tensor。二者同理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eac140c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1.]]),\n",
       " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(4,9), torch.ones((4,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4df3be64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]]]),\n",
       " torch.Size([2, 5, 4]),\n",
       " tensor(40.),\n",
       " torch.Size([]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.ones((2, 5, 4))\n",
    "g, g.shape, g.sum(), g.sum().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5ab9eb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.]]),\n",
       " torch.Size([5, 4]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.sum(axis=0), g.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d3598627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 4])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.sum(axis=0, keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "80128bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 5., 5., 5.],\n",
       "         [5., 5., 5., 5.]]),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.sum(axis=1), g.sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "436fb13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4., 4., 4., 4., 4.],\n",
       "         [4., 4., 4., 4., 4.]]),\n",
       " torch.Size([2, 5]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.sum(axis=2), g.sum(axis=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e35976c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.sum(axis=[0, 2], keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11da988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: torch不区分行向量和列向量吗？\n",
    "### A：一维向量是行向量（长度为n），列向量一定是一个矩阵（行数为n，列数为1）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
