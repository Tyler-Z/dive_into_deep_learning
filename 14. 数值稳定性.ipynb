{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac8bde0",
   "metadata": {},
   "source": [
    "# 1. 数值稳定性\n",
    "\n",
    "## 神经网络的梯度\n",
    "\n",
    "- 向量与向量相乘，得到一个矩阵。做了太多的矩阵乘法\n",
    "<img src=\"./pic/神经网络的梯度.PNG\" width=300 height=300>\n",
    "\n",
    "## 数值稳定性的常见两个问题\n",
    "- 如果梯度的值大于1，如果有100层，可能梯度爆炸\n",
    "- 如果梯度的值小于1，如果有100层，可能梯度消失\n",
    "<img src=\"./pic/数值稳定性的常见两个问题.PNG\" width=300 height=300>\n",
    "\n",
    "\n",
    "## 例子：MLP\n",
    "- 第t层的输出关于第t层输入的导数\n",
    "<img src=\"./pic/例子MLP.PNG\" width=300 height=300>\n",
    "\n",
    "## 梯度爆炸\n",
    "<img src=\"./pic/梯度爆炸.PNG\" width=300 height=300>\n",
    "\n",
    "## 梯度爆炸的问题\n",
    "<img src=\"./pic/梯度爆炸的问题.PNG\" width=300 height=300>\n",
    "\n",
    "## 梯度消失\n",
    "<img src=\"./pic/梯度消失.PNG\" width=500 height=500>\n",
    "<img src=\"./pic/梯度消失2.PNG\" width=500 height=500>\n",
    "\n",
    "## 梯度消失的问题\n",
    "<img src=\"./pic/梯度消失的问题.PNG\" width=300 height=300>\n",
    "\n",
    "## 总结\n",
    "- 当数值过大或者过小时，会导致数值问题\n",
    "- 常发生在深度模型中，因为其会对n个数累乘\n",
    "    - 因为有很多层，梯度就是对n层进行累乘。如果权重稍大，或者前向稍大，会导致梯度爆炸；反之，梯度消失\n",
    "- 既要避免梯度过大，又要避免梯度过小\n",
    "\n",
    "\n",
    " # 2. 【核心】让训练更加稳定\n",
    " - 梯度归一化：把梯度变为均值为0，方差为1\n",
    " - 梯度裁剪：大于5的都等于5，小于0的都等于0\n",
    " <img src=\"./pic/让训练更加稳定.PNG\" width=300 height=300>\n",
    "\n",
    "## 2.1.1 这次重点：合理的权重初始和激活函数\n",
    "- 让每层的方差是一个常数\n",
    "- 随机变量：均值为0，方差为1或某个特定值\n",
    "<img src=\"./pic/让每层的方差是一个常数.PNG\" width=300 height=300>\n",
    "\n",
    "## 2.1.2 权重初始化\n",
    "<img src=\"./pic/权重初始化.PNG\" width=500 height=500>\n",
    "\n",
    "### 2.1.3 例子：MLP\n",
    "- iid：independent identically distributed独立同分布\n",
    "- 均值就是平均值，方差就是判断数据的离散程度，方差大离散程度大\n",
    "<img src=\"./pic/例子MLP2.PNG\" width=500 height=500>\n",
    "\n",
    "### 2.1.4 正向方差\n",
    "- 方差 = 平方的期望 - 期望的平方   现在期望的平方等于0\n",
    "<img src=\"./pic/正向方差.PNG\" width=500 height=500>\n",
    "\n",
    "### 2.1.5 反向均值和方差\n",
    "<img src=\"./pic/反向均值和方差.PNG\" width=500 height=500>\n",
    "\n",
    "### 2.1.6 Xavier初始\n",
    "- 初始化权重时，方差根据输入和输出维度而定\n",
    "<img src=\"./pic/Xavier初始.PNG\" width=500 height=500>\n",
    "\n",
    "## 2.2 假设线性的激活函数\n",
    "<img src=\"./pic/假设线性的激活函数.PNG\" width=500 height=500>\n",
    "\n",
    "### 2.2.1 反向\n",
    "<img src=\"./pic/反向.PNG\" width=500 height=500>\n",
    "\n",
    "### 检查常用激活函数\n",
    "<img src=\"./pic/检查常用激活函数.PNG\" width=500 height=500>\n",
    "\n",
    "\n",
    "## 总结\n",
    "- 合理的权重初始值和激活函数的选取可以提升数值稳定性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05869ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
