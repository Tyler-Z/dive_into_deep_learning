{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe7db5f4",
   "metadata": {},
   "source": [
    "# 多个输入和输出通道\n",
    "\n",
    "- 彩色图像可能有RGB三个通道\n",
    "- 转换为灰度会丢失信息\n",
    "<img src=\"./pic/lena.jpg\" width=300 height=300>\n",
    "\n",
    "\n",
    "## 1. 多个输入通道，单个输出通道\n",
    "\n",
    "- 输入不再是一个矩阵，而是一个三维的张量（tensor）\n",
    "- 每个通道都有一个卷积核，结果是所有通道卷积结果的和\n",
    "<img src=\"./pic/多个输入通道.PNG\" width=500 height=500>\n",
    "- 公式：\n",
    "<img src=\"./pic/多个输入通道公式.PNG\" width=300 height=300>\n",
    "- 最后的输出是**单通道**\n",
    "\n",
    "\n",
    "## 2. 多个输出通道\n",
    "\n",
    "- 不管多少个输入通道，只得到1个输出通道不够。\n",
    "- 增加通道数，使得能够匹配的模式种类增加。相当于同样一个像素，能表达的模式种类，增加了。\n",
    "<img src=\"./pic/多个输出通道.PNG\" width=400 height=400>\n",
    "- c<sub>i</sub>个输入通道，每个输入通道输出c<sub>o</sub>种卷积核，共有c<sub>i</sub> x c<sub>o</sub>种卷积核。\n",
    "    - c<sub>i</sub>：输入通道的（卷积核）层数，\n",
    "    - c<sub>o</sub>：输出通道的（卷积核）层数。（每一个输出通道为了识别某一个特定的模式：提取出不同的特征）\n",
    "    - 两者无相关性 \n",
    "- 对每一个输入X（黄线），拿出对应的一个输出通道的核（黄线），得到一个对应的输出通道（黄线）。然后再把输出通道一一做运算，再concate，得到多个输出通道。\n",
    "\n",
    "\n",
    "## 多个输入和多个输出通道\n",
    "\n",
    "- 每个输出通道可以识别特定模式\n",
    "    - 上篇笔记的骆驼，三个输出通道分别提取边缘特征，锐化特征和高斯特征\n",
    "    - 本例中，输出通道数为6：绿色点，红色点，渐变，斜纹理，竖纹理，模糊\n",
    "\n",
    "<img src=\"./pic/多个输入和多个输出通道.PNG\" width=400 height=400>\n",
    "\n",
    "- 当前层的输入通道把前一层的6种输出通道，组合起来并加权，得到一个组合的模式识别\n",
    "    - 比如纹理比较重要，则纹理权重大，颜色权重小。\n",
    "\n",
    "## 1 x 1 卷积层\n",
    "\n",
    "- 不会识别空间信息\n",
    "    - 因为每次只识别1个像素，不会看这个像素周围的像素\n",
    "- 三个通道压缩成一个通道：融合不同通道的信息\n",
    "<img src=\"./pic/1x1卷积.PNG\" width=400 height=400>\n",
    "\n",
    "- 浅蓝色：三个输入维，输出为第0通道(output channel 0)\n",
    "- 深蓝色：三个输入维，输出为第1通道(output channel 1)\n",
    "- 将 1×1 卷积层看作是在每个像素位置应用的全连接层，以 c<sub>i</sub> 个输入值转换为 c<sub>o</sub> 个输出值\n",
    "    - 相当于输入形状为n<sub>h</sub>n<sub>w</sub> x c<sub>i</sub>，权重为c<sub>i</sub> x c<sub>o</sub>的全连接层\n",
    "- 因为这仍然是一个卷积层，所以跨像素的权重是一致的\n",
    "\n",
    "\n",
    "\n",
    "## 二维卷积层\n",
    "\n",
    "- 输出m的size取决于输入k的size、padding和strides\n",
    "- 一共有 c<sub>i</sub> x c<sub>o</sub> 个卷积核 每个卷积核都有一个偏差\n",
    "<img src=\"./pic/二维卷积层维度.PNG\" width=400 height=400>\n",
    "- 1GFLOP x 10层 x 1M样本 = 10Pflops。\n",
    "\n",
    "## 总结\n",
    "\n",
    "- 输出通道数是卷积层的超参数（输入是前一层的超参数，不是当前层）\n",
    "- 每个输入通道有独立的二维卷积核，所有通道结果相加得到一个输出通道结果\n",
    "- 每个输出通道有独立的三维卷积核，所以最后的卷积核是一个四维的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339d48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):    # X为输入，K为核矩阵\n",
    "    \"\"\"计算二维互相关运算\"\"\"\n",
    "    h, w = K.shape    # 返回行数和列数\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    # 输入的高度：X.shape[0] - h + 1\n",
    "    # 输入的宽度：X.shape[1] - w + 1\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()    # 哈达玛积(不是数学上传统的矩阵乘积)，再求和\n",
    "    return Y\n",
    "\n",
    "# d2l\n",
    "def corr2d(X, K):\n",
    "    \"\"\"Compute 2D cross-correlation.\n",
    "\n",
    "    Defined in :numref:`sec_conv_layer`\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = d2l.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = d2l.reduce_sum((X[i: i + h, j: j + w] * K))\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803910f",
   "metadata": {},
   "source": [
    "# 多输入多输出通道的代码实现\n",
    "## 1. 实现多输入互相关运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f828afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    # 对最外层输入通道做遍历\n",
    "    # 每一次遍历，拿出输入通道的矩阵\n",
    "    # 做互相关运算，最后对元素求和\n",
    "    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))    # 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起\n",
    "\n",
    "# zip函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e3f046d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 1., 2.],\n",
       "          [3., 4., 5.],\n",
       "          [6., 7., 8.]],\n",
       " \n",
       "         [[1., 2., 3.],\n",
       "          [4., 5., 6.],\n",
       "          [7., 8., 9.]]]),\n",
       " torch.Size([2, 3, 3]),\n",
       " tensor([[[0., 1.],\n",
       "          [2., 3.]],\n",
       " \n",
       "         [[1., 2.],\n",
       "          [3., 4.]]]),\n",
       " torch.Size([2, 2, 2]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "X, X.shape, K, K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f6793d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 56.,  72.],\n",
       "         [104., 120.]]),\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d_multi_in(X, K)\n",
    "Y, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf24a151",
   "metadata": {},
   "source": [
    "## 2. 计算多个通道的输出的互相关函数\n",
    "- 上一步是，两层输入一层输出，两层输入和对的卷积核做完卷积运算后求和，变成一层输出\n",
    "- 这一步是，堆叠了三层上一步的操作，就是三组卷积核，一组两个卷积核，所以输出的就是三组卷积核和输入分别做上一步的运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f42f1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 1.],\n",
       "           [2., 3.]],\n",
       " \n",
       "          [[1., 2.],\n",
       "           [3., 4.]]],\n",
       " \n",
       " \n",
       "         [[[1., 2.],\n",
       "           [3., 4.]],\n",
       " \n",
       "          [[2., 3.],\n",
       "           [4., 5.]]],\n",
       " \n",
       " \n",
       "         [[[2., 3.],\n",
       "           [4., 5.]],\n",
       " \n",
       "          [[3., 4.],\n",
       "           [5., 6.]]]]),\n",
       " torch.Size([3, 2, 2, 2]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。\n",
    "    # 最后将所有结果都叠加在一起\n",
    "    # 对K，先拿出k，k为3D tensor\n",
    "    # k与X先做互相关运算，得到一个2D 矩阵\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)\n",
    "\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "K = torch.stack((K, K + 1, K + 2), 0)    # 三个卷积核，每个卷积核有两个通道，每个通道是2*2的矩阵\n",
    "K, K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba67faad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36930ec8",
   "metadata": {},
   "source": [
    "## 1×1  卷积层（等价于一个全连接层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "774b559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))    # h * w：把高和宽拉成一条向量（c_i变成了batch_size）\n",
    "    K = K.reshape((c_o, c_i))      # c_o * c_i * 1 * 1，拿掉最后两个维度\n",
    "    # 全连接层中的矩阵乘法\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))\n",
    "\n",
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)    # 全连接层\n",
    "Y2 = corr2d_multi_in_out(X, K)        # 卷积层\n",
    "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6    # Y1应该等于Y2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb291d",
   "metadata": {},
   "source": [
    "每个通道去识别特定的模式，所以通道之间参数不相同\n",
    "每个通道的卷积核数值是不一样，但卷积核大小size是一样的"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
