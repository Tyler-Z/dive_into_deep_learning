{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf6c65e2",
   "metadata": {},
   "source": [
    "# 1. 池化层（汇聚层）\n",
    "\n",
    "- 卷积对位置太过敏感，但又需要一定程度的平移不变性，所以有池化层\n",
    "<img src=\"./pic/池化层.PNG\" width=400 height=400>\n",
    "\n",
    "## 二维最大池化\n",
    "- 不像卷积层（核与输入做哈达玛积）。而是每次选取窗口中，最大的值\n",
    "\n",
    "<table><tr>\n",
    "    <td><img src=\"./pic/二维最大池化.PNG\" width=300 height=300></td>\n",
    "    <td><img src=\"./pic/二维交叉相关(卷积核).gif\" width=200 height=200></td>\n",
    "</tr></table>\n",
    "<img src=\"./pic/二维最大池化例子1.PNG\" width=400 height=400>\n",
    "- 池化层允许输入发生小偏移，作用在卷积输出上，使输出值附近的小窗口的值都会出现。本质上是池化层对于像素偏移的容忍性\n",
    "\n",
    "\n",
    "## 填充，步幅和多个通道\n",
    "- 与卷积层不同，池化层不会做融合通道。所以输出通道数=输入通道数\n",
    "<table><tr>\n",
    "    <td><img src=\"./pic/填充，步幅和多个通道.PNG\" width=300 height=300></td>\n",
    "    <td><img src=\"./pic/有边界填充，跨步.gif\" width=200 height=200></td>\n",
    "</tr></table>\n",
    "\n",
    "## 平均池化层\n",
    "- 最大池化层：有明显的层次化信息\n",
    "- 平均池化层：抹平信号强度,较柔和，不会有强烈抖动\n",
    "<img src=\"./pic/平均池化层.PNG\" width=300 height=300>\n",
    "\n",
    "\n",
    "## 总结\n",
    "- 池化层返回窗口中最大或平均值\n",
    "- 缓解卷积层对位置的敏感性\n",
    "- 同样有窗口大小、填充、和步幅作为超参数\n",
    "- 没有可以学习的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f54285",
   "metadata": {},
   "source": [
    "# 2. 池化层的实现\n",
    "\n",
    "## 实现池化层的正向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c41c9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3ecf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输入张量X，验证二维最大汇聚层的输出\n",
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef97c036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证平均汇聚层\n",
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24fb1f3",
   "metadata": {},
   "source": [
    "## 填充和步幅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b07cd6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "           [ 4.,  5.,  6.,  7.],\n",
       "           [ 8.,  9., 10., 11.],\n",
       "           [12., 13., 14., 15.]]]]),\n",
       " torch.Size([1, 1, 4, 4]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))    # 批量大小为1，通道为1\n",
    "X, X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56811886",
   "metadata": {},
   "source": [
    "- 深度学习框架中的步幅与汇聚窗口的大小相同\n",
    "    - 看完当前窗口后，下一个窗口与当前窗口不重叠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c9da161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3)    # 3x3的窗口，默认步幅等于窗口size（滑窗不重合）\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da84898b",
   "metadata": {},
   "source": [
    "- 填充和步幅可以手动设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f813d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6e7dde",
   "metadata": {},
   "source": [
    "- 设定一个任意大小的矩形汇聚窗口，并分别设定填充和步幅的高度和宽度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f64af6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  3.],\n",
       "          [ 9., 11.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(1, 1))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd229e33",
   "metadata": {},
   "source": [
    "## 池化层在每个输入通道上单独运算，而不是像卷积层一样在通道上对输入进行汇总"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00dae764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "           [ 4.,  5.,  6.,  7.],\n",
       "           [ 8.,  9., 10., 11.],\n",
       "           [12., 13., 14., 15.]],\n",
       " \n",
       "          [[ 1.,  2.,  3.,  4.],\n",
       "           [ 5.,  6.,  7.,  8.],\n",
       "           [ 9., 10., 11., 12.],\n",
       "           [13., 14., 15., 16.]]]]),\n",
       " torch.Size([1, 2, 4, 4]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))    # 批量大小为1，通道为1\n",
    "X = torch.cat((X, X + 1), 1)    # 要给X加一个通道，所以只能在通道的那一维添加，axis=1\n",
    "X, X.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc28cca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)\n",
    "# 第一个通道和第二个通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09de1c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "           [ 4.,  5.,  6.,  7.],\n",
       "           [ 8.,  9., 10., 11.],\n",
       "           [12., 13., 14., 15.]],\n",
       " \n",
       "          [[ 1.,  2.,  3.,  4.],\n",
       "           [ 5.,  6.,  7.,  8.],\n",
       "           [ 9., 10., 11., 12.],\n",
       "           [13., 14., 15., 16.]]]]),\n",
       " torch.Size([1, 2, 4, 4]),\n",
       " tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "           [ 4.,  5.,  6.,  7.],\n",
       "           [ 8.,  9., 10., 11.],\n",
       "           [12., 13., 14., 15.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  2.,  3.,  4.],\n",
       "           [ 5.,  6.,  7.,  8.],\n",
       "           [ 9., 10., 11., 12.],\n",
       "           [13., 14., 15., 16.]]]]),\n",
       " torch.Size([2, 1, 4, 4]),\n",
       " tensor([[[[[ 0.,  1.,  2.,  3.],\n",
       "            [ 4.,  5.,  6.,  7.],\n",
       "            [ 8.,  9., 10., 11.],\n",
       "            [12., 13., 14., 15.]]]],\n",
       " \n",
       " \n",
       " \n",
       "         [[[[ 1.,  2.,  3.,  4.],\n",
       "            [ 5.,  6.,  7.,  8.],\n",
       "            [ 9., 10., 11., 12.],\n",
       "            [13., 14., 15., 16.]]]]]),\n",
       " torch.Size([2, 1, 1, 4, 4]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q：为什么不用stack而用cat：\n",
    "# A：torch.stack会增加一个新轴，torch.cat只会在某个特定的轴上对元素进行拼接。\n",
    "# 这里a【X】本身已经包含了batch_size和通道两个轴，在通道这个轴上进行的拼接，cat的参数是1\n",
    "a = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))    # 批量大小为1，通道为1\n",
    "b = torch.cat((a, a + 1), 1)    # 上例，轴=1\n",
    "c =  torch.cat((a, a + 1), 0)    # 轴0，变成了2个batch，每个batch只有单通道\n",
    "d = torch.stack((a, a + 1), 0)    # stack：升1维\n",
    "b, b.shape, c, c.shape, d, d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbd5a487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]],\n",
       "\n",
       "\n",
       "        [[[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6a8f53",
   "metadata": {},
   "source": [
    "- Q：为什么现在池化层用的越来越少？\n",
    "- A：池化的目的之一是减少计算，但卷积层strides=2也能减少计算。\n",
    "    - 之二是因为我们会对数据做扰动操作（旋转，缩放）使得神经网络可以看到数据本身发生很多变化。使得数据在卷积层不会过拟合到某个具体的位置\n",
    "    - 所以就淡化的池化层的作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f018fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
